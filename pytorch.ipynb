{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1818.8646528883805\n",
      "199 1258.1428109936319\n",
      "299 872.0386728122604\n",
      "399 605.8798526405612\n",
      "499 422.2060806494055\n",
      "599 295.3196649813514\n",
      "699 207.57194878481425\n",
      "799 146.82849535622387\n",
      "899 104.7368711435385\n",
      "999 75.54153861264342\n",
      "1099 55.27212539529501\n",
      "1199 41.18679720944307\n",
      "1299 31.39012707415213\n",
      "1399 24.57046090960454\n",
      "1499 19.819209083300972\n",
      "1599 16.50637002727583\n",
      "1699 14.194694046330909\n",
      "1799 12.580428816762282\n",
      "1899 11.452371523467786\n",
      "1999 10.66354249241296\n",
      "Result: y = -0.04212234272139479 + 0.8409836406814618 x + 0.00726680503824895 x^2 + -0.09108906421521662 x^3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Create random input and output data\n",
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    # y = a + b x + c x^2 + d x^3\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 343.2263488769531\n",
      "199 231.1525115966797\n",
      "299 156.69113159179688\n",
      "399 107.20372772216797\n",
      "499 74.30345916748047\n",
      "599 52.42295837402344\n",
      "699 37.865821838378906\n",
      "799 28.17734146118164\n",
      "899 21.726423263549805\n",
      "999 17.429397583007812\n",
      "1099 14.565776824951172\n",
      "1199 12.656444549560547\n",
      "1299 11.382793426513672\n",
      "1399 10.532732963562012\n",
      "1499 9.965065002441406\n",
      "1599 9.585763931274414\n",
      "1699 9.33215618133545\n",
      "1799 9.162482261657715\n",
      "1899 9.048893928527832\n",
      "1999 8.972790718078613\n",
      "Result: y = 0.006393132731318474 + 0.8461303114891052 x + -0.0011029209708794951 x^2 + -0.09182112663984299 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: <built-in method type of Tensor object at 0x7f13d2f762c0>\n",
      "Array Shape: torch.Size([2, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[[[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "         [[[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]],\n",
      "\n",
      "          [[1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1.]]]]])\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/kanncaa1/pytorch-tutorial-for-deep-learning-lovers\n",
    "array = [\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "]\n",
    "tensor = torch.Tensor(array)\n",
    "print(\"Array Type: {}\".format(tensor.type)) # type\n",
    "print(\"Array Shape: {}\".format(tensor.shape)) # shape\n",
    "print(tensor)\n",
    "\n",
    "test_shape = torch.ones([10, 4, 2, 4, 4])\n",
    "print(test_shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommandation-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
